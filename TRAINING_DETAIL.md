
# 🧠 Detailed Training Process: Emotion Detection ResNet

이 문서는 본 프로젝트의 감정 인식 모델이 어떤 데이터를 사용했고, 어떻게 학습되었는지에 대한 상세한 기술적 리포트입니다.

---

## 1. 데이터셋 및 분류 (Dataset & Classification)

본 프로젝트는 모델의 신뢰도를 높이기 위해 대규모의 **한국인 안면 감정인식 데이터**를 활용했습니다.

### 1.1 데이터 출처
- **Source**: AI Hub "한국인 감정인식을 위한 복합 영상" 데이터셋
- **구성**: 수만 명의 한국인 피실험자가 다양한 상황에서 짓는 감정 표정을 담은 영상 프레임

### 1.2 감정 분류 (Labeling)
데이터는 압축 파일(`.zip`) 형태로 제공되었으며, 파일명에 포함된 키워드를 추출하여 자동으로 라벨링을 수행했습니다.
- **Neutral (중립)**: 파일명에 `중립` 또는 `Neutral` 키워드가 포함된 이미지 (Label: 0)
- **Anxious (불안)**: 파일명에 `불안` 또는 `Anxiety` 키워드가 포함된 이미지 (Label: 1)
- **제외 데이터**: 노이즈가 섞인 데이터나 기타 감정(슬픔, 기쁨 등)은 본 '불안 탐지' 목적에서 제외하여 이진 분류(Binary Classification)로 최적화했습니다.

### 1.3 데이터 샘플링 및 구성
- **샘플링 전략**: 각 감정별 수만 장의 데이터 중, 학습 효율을 위해 각 ZIP 파일당 최대 5,000개의 프레임을 무작위 또는 일정 간격으로 샘플링하였습니다.
- **데이터 로드**: 총 100,000장 이상의 이미지에서 랜드마크를 추출하여 학습에 사용했습니다.
- **독립 검증 셋**: `Validation` 폴더의 데이터는 학습에 단 1%도 포함시키지 않고, 오직 최종 모델의 **'실전 성능'**을 테스트하는 용도로만 사용했습니다.

---

## 2. 데이터 전처리 (Data Preprocessing)

감정 인식의 핵심은 조명이나 배경에 무관하게 얼굴의 **"형태(Geometry)"** 변화를 포착하는 것입니다.

### 2.1 MediaPipe FaceMesh 활용
- **피처 추출**: MediaPipe FaceMesh를 통해 얼굴의 478개 핵심 랜드마크를 3D 좌표(x, y, z)로 추출합니다.
- **데이터 효율성**: 이미지 전체를 학습시키는 대신, 1,434개의 숫자(좌표값)만 사용하므로 모델이 매우 가볍고(약 10MB) 추론 속도가 압도적으로 빠릅니다.

### 2.2 좌표 정규화 (Normalization)
서로 다른 얼굴 크기와 카메라 거리를 극복하기 위한 필수 과정입니다.
1.  **중심 이동 (Translation)**: 얼굴의 중심인 '코 끝'을 (0,0,0) 좌표로 이동시켜 모든 데이터를 원점을 기준으로 정렬합니다.
2.  **스케일링 (Scaling)**: 중심에서 가장 먼 지점까지의 거리를 1로 정규화합니다. 이 과정을 통해 모델은 얼굴의 **'절대적인 크기'**가 아닌 **'상대적인 비율'**과 **'왜곡'**만을 학습하게 됩니다.

---

## 3. 모델 아키텍처 (Model Architecture)

기존의 단순 MLP 구조에서 발생하는 성능 정체(85% 벽)를 해결하기 위해 **ResNet(Residual Network)** 스타일을 도입했습니다.

### 3.1 Residual MLP 구조
- **Skip Connection**: 층을 지날 때 이전 층의 정보를 더해주는 방식으로, 네트워크가 깊어져도 '기울기 소실(Gradient Vanishing)' 문제 없이 세밀한 표정 변화를 학습할 수 있게 했습니다.
- **GELU Activation**: 0 부근에서 부드럽게 꺾이는 GELU 활성화 함수를 사용하여, 미세한 입꼬리나 눈썹의 변화를 더 잘 감지하도록 했습니다.

---

## 4. 학습 최적화 기법 (Optimization)

전략적인 학습을 통해 과적합을 방지하고 일반화 성능을 극대화했습니다.

- **Noise Injection**: 훈련 시 좌표값에 가우시안 노이즈를 미세하게 섞어, 모델이 특정 포인트에 집착하지 않고 전체적인 '인상'을 학습하도록 유도했습니다.
- **Label Smoothing (0.05)**: 모델이 정답에 대해 100% 확신하지 않도록 하여, 약간의 예외 상황(개인마다 다른 표정 습관)을 수용할 수 있는 유연한 모델을 만들었습니다.
- **Cosine Annealing LR**: 학습이 진행될수록 학습률(Learning Rate)을 부드럽게 줄여 최적의 가중치를 정밀하게 찾아냈습니다.

---

## 5. 최종 성능 지표 (Strict Evaluation)

학습 데이터와 완전히 분리된 **Validation** 데이터셋에 대한 결과입니다.

- **전체 정확도 (Accuracy)**: **85.2%**
- **Anxious Recall (불안 감지)**: **86%** (실제 불안한 표정을 놓치지 않고 잡아내는 능력)
- **Neutral Precision (중립 신뢰도)**: **85%** (중립이라고 판단했을 때의 정확도)

이 수치는 모델이 한 번도 보지 못한 완전히 새로운 인물의 얼굴에서도 안정적으로 감정을 맞출 수 있음을 의미합니다.
